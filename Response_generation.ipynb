{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Response_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPblI/Hkipvq+UPRf8XipNS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azhar-999-coder/conversational_bot/blob/master/Response_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcmJYFL4C7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, GRU\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_words=30000\n",
        "max_length=30\n",
        "Tx = max_length\n",
        "Ty = max_length\n",
        "\n",
        "def preprocess(path):\n",
        "    dirlist = os.listdir(path)\n",
        "    human_sentences=[]\n",
        "    machine_sentences=[]\n",
        "    for File in dirlist:\n",
        "        with open(path+\"/\"+File, 'r') as raw_lines:\n",
        "            lineList = []\n",
        "            while True:        \n",
        "                line = raw_lines.readline()\n",
        "                if not line:\n",
        "                    break\n",
        "                lineList.append(line)\n",
        "\n",
        "        for i in range(0, len(lineList)):\n",
        "            if(i%2)==0:\n",
        "                human_sentences.append(lineList[i])\n",
        "            else:\n",
        "                machine_sentences.append(lineList[i])    \n",
        "\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(human_sentences)\n",
        "    human_word_index = tokenizer.word_index\n",
        "    human_reverse_word_index = {a:b for (b,a) in human_word_index.items()}\n",
        "\n",
        "    tokenizer2 = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "    \n",
        "    tokenizer2.fit_on_texts(machine_sentences)\n",
        "    machine_word_index = tokenizer2.word_index\n",
        "    machine_reverse_word_index = {a:b for (b,a) in machine_word_index.items()}\n",
        "\n",
        "    human_sequences = tokenizer.texts_to_sequences(human_sentences)\n",
        "    human_padded = tf.keras.preprocessing.sequence.pad_sequences(human_sequences, maxlen=max_length, truncating = \"post\")\n",
        "\n",
        "    machine_sequences = tokenizer2.texts_to_sequences(machine_sentences)\n",
        "    machine_padded = tf.keras.preprocessing.sequence.pad_sequences(machine_sequences, maxlen=max_length, truncating = \"post\")  \n",
        "\n",
        "\n",
        "    return human_padded, machine_padded, human_word_index, human_reverse_word_index, machine_word_index, machine_reverse_word_index\n",
        "\n",
        "X, Y, human_vocab, reverse_human_vocab, machine_vocab, reverse_machine_vocab = preprocess('Data/')\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivk54BuP4OSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "855e50f8-355b-4f85-df54-5eebe69eb20a"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-21 08:58:14--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2020-06-21 08:58:14--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2020-06-21 08:58:15--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  2.23MB/s    in 11m 43s \n",
            "\n",
            "2020-06-21 09:09:59 (2.06 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BX16zAwFr_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "82db0054-2906-4bb4-92a3-8aba1bdb7300"
      },
      "source": [
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSJk96ubIwKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7777be21-df2c-4e7f-c522-dc38f91fc083"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.twitter.27B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi8pn-RZJ3Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim=100\n",
        "embedding_matrix = np.zeros((len(human_vocab)+1, embedding_dim))\n",
        "for word, i in human_vocab.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtW_HkY_BhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QShnjewCKSdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddingLayer = tf.keras.layers.Embedding((len(human_vocab)+1),embedding_dim, weights=[embedding_matrix], trainable=False, input_length=max_length)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9gv7cw1LaAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = embeddingLayer\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKoet15y7mQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, hidden_state, values):\n",
        "    hidden_state_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    concat = self.V(tf.nn.tanh(\n",
        "        self.W1(hidden_state_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(concat, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX3VnWhcT5mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_s, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.n_s = n_s\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding = embeddingLayer\n",
        "    self.gru = GRU(self.n_s, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.attention = BahdanauAttention(n_s)\n",
        "    self.fc = Dense(n_s)\n",
        "\n",
        "  def call(self, x, hidden, encoder_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33Jv4vvNXS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=len(X)\n",
        "n_a = 64\n",
        "n_s = 64"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnueMSXWk9S-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "\n",
        "  inputs = Input(shape=(30,))\n",
        "    \n",
        "  encoder = Encoder(human_vocab_size, embedding_dim, n_a, BATCH_SIZE)\n",
        "\n",
        "  hidden = encoder.initialize_hidden_state()\n",
        "  output, hidden = encoder(inputs, hidden)\n",
        "  \n",
        "  attention_layer = BahdanauAttention(10)\n",
        "  context, attention_weights = attention_layer(hidden, output)\n",
        "\n",
        "  decoder = Decoder(machine_vocab_size, embedding_dim, n_s, BATCH_SIZE)\n",
        "\n",
        "  outputs = []\n",
        "  for t in range (0,Ty):\n",
        "    x, state, attention_weights = decoder.decode(tf.random.uniform((BATCH_SIZE, 1)), hidden, output)\n",
        "    outputs.append(x)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QekBmEmL4uQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model(n_a,n_s,len(human_vocab),len(machine_vocab))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWLuEJ_h4-Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUnMvXYUbGIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33033db0-550c-4197-aeec-3a11721afe10"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1 (Encoder)             ((50000, 30, 64), (5 942672      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bahdanau_attention_3 (BahdanauA ((50000, 64), (50000 16769       encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_30 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_31 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_32 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[2][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_33 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[3][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_34 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[4][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_35 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[5][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_36 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[6][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_37 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[7][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_38 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[8][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_39 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[9][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_40 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[10][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_41 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[11][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_42 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[12][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_43 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[13][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_44 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[14][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_45 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[15][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_46 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[16][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_47 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[17][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_48 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[18][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_49 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[19][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_50 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[20][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_51 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[21][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_52 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[22][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_53 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[23][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_54 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[24][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_55 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[25][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_56 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[26][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_57 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[27][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_58 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[28][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_59 (Tens [(50000, 1, 64)]     0           bahdanau_attention_3[29][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_30 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_31 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_32 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_33 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_34 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_35 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_36 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_37 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_38 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_39 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_40 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_41 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_42 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_43 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_44 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_45 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_46 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_47 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_48 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_49 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_50 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_51 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_52 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_53 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_54 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_55 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_56 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_57 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_58 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_59 (TensorFl [(50000, 1, 164)]    0           tf_op_layer_ExpandDims_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "gru_3 (GRU)                     [(50000, 1, 128), (5 112896      tf_op_layer_concat_30[0][0]      \n",
            "                                                                 tf_op_layer_concat_31[0][0]      \n",
            "                                                                 tf_op_layer_concat_32[0][0]      \n",
            "                                                                 tf_op_layer_concat_33[0][0]      \n",
            "                                                                 tf_op_layer_concat_34[0][0]      \n",
            "                                                                 tf_op_layer_concat_35[0][0]      \n",
            "                                                                 tf_op_layer_concat_36[0][0]      \n",
            "                                                                 tf_op_layer_concat_37[0][0]      \n",
            "                                                                 tf_op_layer_concat_38[0][0]      \n",
            "                                                                 tf_op_layer_concat_39[0][0]      \n",
            "                                                                 tf_op_layer_concat_40[0][0]      \n",
            "                                                                 tf_op_layer_concat_41[0][0]      \n",
            "                                                                 tf_op_layer_concat_42[0][0]      \n",
            "                                                                 tf_op_layer_concat_43[0][0]      \n",
            "                                                                 tf_op_layer_concat_44[0][0]      \n",
            "                                                                 tf_op_layer_concat_45[0][0]      \n",
            "                                                                 tf_op_layer_concat_46[0][0]      \n",
            "                                                                 tf_op_layer_concat_47[0][0]      \n",
            "                                                                 tf_op_layer_concat_48[0][0]      \n",
            "                                                                 tf_op_layer_concat_49[0][0]      \n",
            "                                                                 tf_op_layer_concat_50[0][0]      \n",
            "                                                                 tf_op_layer_concat_51[0][0]      \n",
            "                                                                 tf_op_layer_concat_52[0][0]      \n",
            "                                                                 tf_op_layer_concat_53[0][0]      \n",
            "                                                                 tf_op_layer_concat_54[0][0]      \n",
            "                                                                 tf_op_layer_concat_55[0][0]      \n",
            "                                                                 tf_op_layer_concat_56[0][0]      \n",
            "                                                                 tf_op_layer_concat_57[0][0]      \n",
            "                                                                 tf_op_layer_concat_58[0][0]      \n",
            "                                                                 tf_op_layer_concat_59[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_30 (TensorF [(50000, 128)]       0           gru_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_31 (TensorF [(50000, 128)]       0           gru_3[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_32 (TensorF [(50000, 128)]       0           gru_3[2][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_33 (TensorF [(50000, 128)]       0           gru_3[3][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_34 (TensorF [(50000, 128)]       0           gru_3[4][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_35 (TensorF [(50000, 128)]       0           gru_3[5][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_36 (TensorF [(50000, 128)]       0           gru_3[6][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_37 (TensorF [(50000, 128)]       0           gru_3[7][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_38 (TensorF [(50000, 128)]       0           gru_3[8][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_39 (TensorF [(50000, 128)]       0           gru_3[9][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_40 (TensorF [(50000, 128)]       0           gru_3[10][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_41 (TensorF [(50000, 128)]       0           gru_3[11][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_42 (TensorF [(50000, 128)]       0           gru_3[12][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_43 (TensorF [(50000, 128)]       0           gru_3[13][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_44 (TensorF [(50000, 128)]       0           gru_3[14][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_45 (TensorF [(50000, 128)]       0           gru_3[15][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_46 (TensorF [(50000, 128)]       0           gru_3[16][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_47 (TensorF [(50000, 128)]       0           gru_3[17][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_48 (TensorF [(50000, 128)]       0           gru_3[18][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_49 (TensorF [(50000, 128)]       0           gru_3[19][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_50 (TensorF [(50000, 128)]       0           gru_3[20][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_51 (TensorF [(50000, 128)]       0           gru_3[21][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_52 (TensorF [(50000, 128)]       0           gru_3[22][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_53 (TensorF [(50000, 128)]       0           gru_3[23][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_54 (TensorF [(50000, 128)]       0           gru_3[24][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_55 (TensorF [(50000, 128)]       0           gru_3[25][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_56 (TensorF [(50000, 128)]       0           gru_3[26][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_57 (TensorF [(50000, 128)]       0           gru_3[27][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_58 (TensorF [(50000, 128)]       0           gru_3[28][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_59 (TensorF [(50000, 128)]       0           gru_3[29][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (50000, 128)         16512       tf_op_layer_Reshape_30[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_31[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_32[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_33[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_34[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_35[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_36[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_37[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_38[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_39[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_40[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_41[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_42[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_43[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_44[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_45[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_46[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_47[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_48[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_49[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_50[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_51[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_52[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_53[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_54[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_55[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_56[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_57[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_58[0][0]     \n",
            "                                                                 tf_op_layer_Reshape_59[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 1,088,849\n",
            "Trainable params: 178,049\n",
            "Non-trainable params: 910,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-G1ZfOjeMoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "56e2dd90-d162-490b-9790-ad21c6525d9c"
      },
      "source": [
        "model.fit(X,Y, epochs=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9b2993aaae21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  [_Derived_]  Incompatible shapes: [32,64] vs. [50000,64]\n\t [[{{node while_21/body/_1/add}}]]\n\t [[model_1/encoder_1/gru_2/StatefulPartitionedCall]] [Op:__inference_train_function_91702]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTYbyqIjrFMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cbc2bf97-1201-4f90-88dc-8a9aa0f1f57d"
      },
      "source": [
        "print(Y.shape)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VpLYzxnfKHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbddZTTbGccO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(len(human_vocab), embedding_dim, n_a, BATCH_SIZE)\n",
        "decoder = Decoder(len(machine_vocab), embedding_dim, n_s, BATCH_SIZE)\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([machine_vocab['<OOV>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuD3m-onGfz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "e56a38c9-1c40-4e00-e0df-ed3327fa477d"
      },
      "source": [
        "EPOCHS = 10\n",
        "inp = X\n",
        "targ=Y\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  batch_loss = train_step(inp, targ, enc_hidden)\n",
        "  total_loss += batch_loss\n",
        "\n",
        "  if batch % 100 == 0:\n",
        "    print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-63d6f36152da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg2fCp8Leobl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}